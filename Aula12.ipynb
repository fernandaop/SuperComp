{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4iw_xdXgGGs",
        "outputId": "3658c231-92a7-4794-fc57-ae002eb35fcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing magnitude_comparison.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile magnitude_comparison.cu\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <chrono>  // Para medir o tempo de execução\n",
        "#include <cuda.h>\n",
        "\n",
        "// Kernel para calcular os quadrados dos elementos do vetor na GPU\n",
        "__global__ void square_elements(float *v, float *result, int N) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < N) {\n",
        "        result[idx] = v[idx] * v[idx];  // Elevar ao quadrado cada elemento\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função para calcular a magnitude na GPU\n",
        "float magnitude_gpu(float *h_v, int N) {\n",
        "    float *d_v, *d_result;\n",
        "\n",
        "    // Alocar memória na GPU\n",
        "    cudaMalloc(&d_v, N * sizeof(float));\n",
        "    cudaMalloc(&d_result, N * sizeof(float));\n",
        "\n",
        "    // Copiar vetor da CPU para a GPU\n",
        "    cudaMemcpy(d_v, h_v, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configuração dos blocos e threads\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Executar o kernel para calcular os quadrados dos elementos\n",
        "    square_elements<<<blocksPerGrid, threadsPerBlock>>>(d_v, d_result, N);\n",
        "\n",
        "    // Copiar o resultado de volta para a CPU\n",
        "    float *h_result = new float[N];\n",
        "    cudaMemcpy(h_result, d_result, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Somar todos os quadrados e calcular a magnitude\n",
        "    float sum_of_squares = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum_of_squares += h_result[i];\n",
        "    }\n",
        "\n",
        "    // Liberar memória na GPU\n",
        "    cudaFree(d_v);\n",
        "    cudaFree(d_result);\n",
        "    delete[] h_result;\n",
        "\n",
        "    // Retornar a magnitude\n",
        "    return std::sqrt(sum_of_squares);\n",
        "}\n",
        "\n",
        "// Função para calcular a magnitude na CPU\n",
        "float magnitude_cpu(float *v, int N) {\n",
        "    float sum_of_squares = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        sum_of_squares += v[i] * v[i];\n",
        "    }\n",
        "    return std::sqrt(sum_of_squares);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Tamanho do vetor\n",
        "    int N = 1000000;\n",
        "\n",
        "    // Alocar e inicializar o vetor com valores aleatórios\n",
        "    float *v = new float[N];\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        v[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Calcular a magnitude na CPU e medir o tempo\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "    float mag_cpu = magnitude_cpu(v, N);\n",
        "    auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<float> duration_cpu = end_cpu - start_cpu;\n",
        "    std::cout << \"Magnitude na CPU: \" << mag_cpu << std::endl;\n",
        "    std::cout << \"Tempo de execução na CPU: \" << duration_cpu.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    // Calcular a magnitude na GPU e medir o tempo\n",
        "    auto start_gpu = std::chrono::high_resolution_clock::now();\n",
        "    float mag_gpu = magnitude_gpu(v, N);\n",
        "    auto end_gpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<float> duration_gpu = end_gpu - start_gpu;\n",
        "    std::cout << \"Magnitude na GPU: \" << mag_gpu << std::endl;\n",
        "    std::cout << \"Tempo de execução na GPU: \" << duration_gpu.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    // Liberar memória da CPU\n",
        "    delete[] v;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc magnitude_comparison.cu -o magnitude_comparison\n"
      ],
      "metadata": {
        "id": "aFwOsqoitpuK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./magnitude_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmJ7OeeUtp58",
        "outputId": "90310a31-1c97-4195-a09d-43e3434a7480"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Magnitude na CPU: 577.228\n",
            "Tempo de execução na CPU: 0.00386753 segundos\n",
            "Magnitude na GPU: 0\n",
            "Tempo de execução na GPU: 0.0049066 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile variance_comparison.cu\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <chrono>  // Para medir o tempo de execução\n",
        "#include <cuda.h>\n",
        "\n",
        "// Kernel para calcular a média de um vetor\n",
        "__global__ void mean_kernel(float *v, float *mean, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        atomicAdd(mean, v[idx] / N);  // Atomic para garantir a soma correta entre as threads\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para calcular a diferença ao quadrado para a variância\n",
        "__global__ void variance_kernel(float *v, float mean, float *result, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        float diff = v[idx] - mean;\n",
        "        atomicAdd(result, diff * diff / N);  // Soma das diferenças ao quadrado\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função que calcula a variância em etapas separadas na GPU\n",
        "float variance_separate_gpu(float *h_v, int N) {\n",
        "    float *d_v, *d_mean, *d_variance;\n",
        "    float h_mean = 0.0f, h_variance = 0.0f;\n",
        "\n",
        "    // Alocar memória na GPU\n",
        "    cudaMalloc(&d_v, N * sizeof(float));\n",
        "    cudaMalloc(&d_mean, sizeof(float));\n",
        "    cudaMalloc(&d_variance, sizeof(float));\n",
        "\n",
        "    // Copiar o vetor da CPU para a GPU\n",
        "    cudaMemcpy(d_v, h_v, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mean, &h_mean, sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_variance, &h_variance, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configurar grid e block\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Calcular a média\n",
        "    mean_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, d_mean, N);\n",
        "    cudaMemcpy(&h_mean, d_mean, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Calcular a variância\n",
        "    variance_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, h_mean, d_variance, N);\n",
        "    cudaMemcpy(&h_variance, d_variance, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Liberar a memória da GPU\n",
        "    cudaFree(d_v);\n",
        "    cudaFree(d_mean);\n",
        "    cudaFree(d_variance);\n",
        "\n",
        "    return h_variance;\n",
        "}\n",
        "\n",
        "// Fusion Kernel: Calcular variância em uma única etapa\n",
        "__global__ void variance_fusion_kernel(float *v, float *result, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        // Primeira fase: cálculo da média\n",
        "        __shared__ float mean;\n",
        "        mean = 0.0f;\n",
        "        atomicAdd(&mean, v[idx] / N);\n",
        "        __syncthreads();  // Espera a finalização do cálculo da média\n",
        "\n",
        "        // Segunda fase: cálculo da variância em uma única operação\n",
        "        float diff = v[idx] - mean;\n",
        "        atomicAdd(result, diff * diff / N);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função que calcula a variância usando fusion kernel na GPU\n",
        "float variance_fusion_gpu(float *h_v, int N) {\n",
        "    float *d_v, *d_variance;\n",
        "    float h_variance = 0.0f;\n",
        "\n",
        "    // Alocar memória na GPU\n",
        "    cudaMalloc(&d_v, N * sizeof(float));\n",
        "    cudaMalloc(&d_variance, sizeof(float));\n",
        "\n",
        "    // Copiar o vetor da CPU para a GPU\n",
        "    cudaMemcpy(d_v, h_v, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_variance, &h_variance, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Configurar grid e block\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Executar o kernel de variância com fusão\n",
        "    variance_fusion_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, d_variance, N);\n",
        "    cudaMemcpy(&h_variance, d_variance, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Liberar a memória da GPU\n",
        "    cudaFree(d_v);\n",
        "    cudaFree(d_variance);\n",
        "\n",
        "    return h_variance;\n",
        "}\n",
        "\n",
        "// Função para calcular a variância na CPU\n",
        "float variance_cpu(float *v, int N) {\n",
        "    float mean = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        mean += v[i];\n",
        "    }\n",
        "    mean /= N;\n",
        "\n",
        "    float variance = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float diff = v[i] - mean;\n",
        "        variance += diff * diff;\n",
        "    }\n",
        "    return variance / N;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Tamanhos dos vetores\n",
        "    int N1 = 100000;\n",
        "    int N2 = 1000000;\n",
        "\n",
        "    // Vetores na CPU\n",
        "    float *v1 = new float[N1];\n",
        "    float *v2 = new float[N2];\n",
        "\n",
        "    // Inicializar os vetores com valores aleatórios\n",
        "    for (int i = 0; i < N1; i++) {\n",
        "        v1[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "    for (int i = 0; i < N2; i++) {\n",
        "        v2[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    // Variância na CPU\n",
        "    auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "    float var_cpu1 = variance_cpu(v1, N1);\n",
        "    auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<float> duration_cpu1 = end_cpu - start_cpu;\n",
        "\n",
        "    // Variância separada na GPU\n",
        "    auto start_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "    float var_gpu_sep1 = variance_separate_gpu(v1, N1);\n",
        "    auto end_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<float> duration_gpu_sep1 = end_gpu_sep - start_gpu_sep;\n",
        "\n",
        "    // Variância com fusion kernel na GPU\n",
        "    auto start_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "    float var_gpu_fusion1 = variance_fusion_gpu(v1, N1);\n",
        "    auto end_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<float> duration_gpu_fusion1 = end_gpu_fusion - start_gpu_fusion;\n",
        "\n",
        "    // Imprimir resultados\n",
        "    std::cout << \"Tamanho N1 = \" << N1 << std::endl;\n",
        "    std::cout << \"Variância CPU: \" << var_cpu1 << \" | Tempo CPU: \" << duration_cpu1.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Variância GPU (etapas separadas): \" << var_gpu_sep1 << \" | Tempo GPU: \" << duration_gpu_sep1.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Variância GPU (fusion kernel): \" << var_gpu_fusion1 << \" | Tempo GPU: \" << duration_gpu_fusion1.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    // Testar com o vetor maior N2\n",
        "    // Variância CPU\n",
        "    start_cpu = std::chrono::high_resolution_clock::now();\n",
        "    float var_cpu2 = variance_cpu(v2, N2);\n",
        "    end_cpu = std::chrono::high_resolution_clock::now();\n",
        "    duration_cpu1 = end_cpu - start_cpu;\n",
        "\n",
        "    // Variância separada na GPU\n",
        "    start_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "    float var_gpu_sep2 = variance_separate_gpu(v2, N2);\n",
        "    end_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "    duration_gpu_sep1 = end_gpu_sep - start_gpu_sep;\n",
        "\n",
        "    // Variância com fusion kernel na GPU\n",
        "    start_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "    float var_gpu_fusion2 = variance_fusion_gpu(v2, N2);\n",
        "    end_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "    duration_gpu_fusion1 = end_gpu_fusion - start_gpu_fusion;\n",
        "\n",
        "    // Imprimir resultados\n",
        "    std::cout << \"\\nTamanho N2 = \" << N2 << std::endl;\n",
        "    std::cout << \"Variância CPU: \" << var_cpu2 << \" | Tempo CPU: \" << duration_cpu1.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Variância GPU (etapas separadas): \" << var_gpu_sep2 << \" | Tempo GPU: \" << duration_gpu_sep1.count() << \" segundos\" << std::endl;\n",
        "    std::cout << \"Variância GPU (fusion kernel): \" << var_gpu_fusion2 << \" | Tempo GPU: \" << duration_gpu_fusion1.count() << \" segundos\" << std::endl;\n",
        "\n",
        "    // Liberar a memória\n",
        "    delete[] v1;\n",
        "    delete[] v2;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gMpK0oCuLeq",
        "outputId": "585ccf16-6f14-4c75-83c7-6b79ab59eeb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing variance_comparison.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc variance_comparison.cu -o variance_comparison\n"
      ],
      "metadata": {
        "id": "3JWAjch_uSnV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./variance_comparison\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvRxmdzluSwZ",
        "outputId": "05eea66b-d7b0-4808-bd18-1b5f6ae554aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho N1 = 100000\n",
            "Variância CPU: 0.083289 | Tempo CPU: 0.000694844 segundos\n",
            "Variância GPU (etapas separadas): 0 | Tempo GPU: 0.000238345 segundos\n",
            "Variância GPU (fusion kernel): 0 | Tempo GPU: 4.5e-07 segundos\n",
            "\n",
            "Tamanho N2 = 1000000\n",
            "Variância CPU: 0.0832533 | Tempo CPU: 0.00689089 segundos\n",
            "Variância GPU (etapas separadas): 0 | Tempo GPU: 5.149e-06 segundos\n",
            "Variância GPU (fusion kernel): 0 | Tempo GPU: 3.32e-07 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile variance_comparison2.cu\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <chrono>\n",
        "#include <cuda.h>\n",
        "\n",
        "// Kernel para calcular a média de um vetor\n",
        "__global__ void mean_kernel(float *v, float *mean, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        atomicAdd(mean, v[idx] / N);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel para calcular a diferença ao quadrado para a variância\n",
        "__global__ void variance_kernel(float *v, float mean, float *result, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        float diff = v[idx] - mean;\n",
        "        atomicAdd(result, diff * diff / N);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função que calcula a variância em etapas separadas na GPU\n",
        "float variance_separate_gpu(float *h_v, int N) {\n",
        "    float *d_v, *d_mean, *d_variance;\n",
        "    float h_mean = 0.0f, h_variance = 0.0f;\n",
        "\n",
        "    cudaMalloc(&d_v, N * sizeof(float));\n",
        "    cudaMalloc(&d_mean, sizeof(float));\n",
        "    cudaMalloc(&d_variance, sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_v, h_v, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mean, &h_mean, sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_variance, &h_variance, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    mean_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, d_mean, N);\n",
        "    cudaMemcpy(&h_mean, d_mean, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    variance_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, h_mean, d_variance, N);\n",
        "    cudaMemcpy(&h_variance, d_variance, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_v);\n",
        "    cudaFree(d_mean);\n",
        "    cudaFree(d_variance);\n",
        "\n",
        "    return h_variance;\n",
        "}\n",
        "\n",
        "// Fusion Kernel\n",
        "__global__ void variance_fusion_kernel(float *v, float *result, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < N) {\n",
        "        __shared__ float mean;\n",
        "        mean = 0.0f;\n",
        "        atomicAdd(&mean, v[idx] / N);\n",
        "        __syncthreads();\n",
        "\n",
        "        float diff = v[idx] - mean;\n",
        "        atomicAdd(result, diff * diff / N);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Função que calcula a variância usando fusion kernel na GPU\n",
        "float variance_fusion_gpu(float *h_v, int N) {\n",
        "    float *d_v, *d_variance;\n",
        "    float h_variance = 0.0f;\n",
        "\n",
        "    cudaMalloc(&d_v, N * sizeof(float));\n",
        "    cudaMalloc(&d_variance, sizeof(float));\n",
        "\n",
        "    cudaMemcpy(d_v, h_v, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_variance, &h_variance, sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    variance_fusion_kernel<<<blocksPerGrid, threadsPerBlock>>>(d_v, d_variance, N);\n",
        "    cudaMemcpy(&h_variance, d_variance, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_v);\n",
        "    cudaFree(d_variance);\n",
        "\n",
        "    return h_variance;\n",
        "}\n",
        "\n",
        "// Função para calcular a variância na CPU\n",
        "float variance_cpu(float *v, int N) {\n",
        "    float mean = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        mean += v[i];\n",
        "    }\n",
        "    mean /= N;\n",
        "\n",
        "    float variance = 0.0f;\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        float diff = v[i] - mean;\n",
        "        variance += diff * diff;\n",
        "    }\n",
        "    return variance / N;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Tamanhos dos vetores\n",
        "    int sizes[] = {100000, 1000000, 10000000, 100000000};\n",
        "    int num_sizes = sizeof(sizes) / sizeof(sizes[0]);\n",
        "\n",
        "    // Iterar sobre cada tamanho de vetor\n",
        "    for (int i = 0; i < num_sizes; i++) {\n",
        "        int N = sizes[i];\n",
        "\n",
        "        // Vetor na CPU\n",
        "        float *v = new float[N];\n",
        "\n",
        "        // Inicializar o vetor com valores aleatórios\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            v[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        }\n",
        "\n",
        "        std::cout << \"\\nTamanho N = \" << N << std::endl;\n",
        "\n",
        "        // Variância na CPU\n",
        "        auto start_cpu = std::chrono::high_resolution_clock::now();\n",
        "        float var_cpu = variance_cpu(v, N);\n",
        "        auto end_cpu = std::chrono::high_resolution_clock::now();\n",
        "        std::chrono::duration<float> duration_cpu = end_cpu - start_cpu;\n",
        "        std::cout << \"Variância CPU: \" << var_cpu << \" | Tempo CPU: \" << duration_cpu.count() << \" segundos\" << std::endl;\n",
        "\n",
        "        // Variância separada na GPU\n",
        "        auto start_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "        float var_gpu_sep = variance_separate_gpu(v, N);\n",
        "        auto end_gpu_sep = std::chrono::high_resolution_clock::now();\n",
        "        std::chrono::duration<float> duration_gpu_sep = end_gpu_sep - start_gpu_sep;\n",
        "        std::cout << \"Variância GPU (etapas separadas): \" << var_gpu_sep << \" | Tempo GPU: \" << duration_gpu_sep.count() << \" segundos\" << std::endl;\n",
        "\n",
        "        // Variância com fusion kernel na GPU\n",
        "        auto start_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "        float var_gpu_fusion = variance_fusion_gpu(v, N);\n",
        "        auto end_gpu_fusion = std::chrono::high_resolution_clock::now();\n",
        "        std::chrono::duration<float> duration_gpu_fusion = end_gpu_fusion - start_gpu_fusion;\n",
        "        std::cout << \"Variância GPU (fusion kernel): \" << var_gpu_fusion << \" | Tempo GPU: \" << duration_gpu_fusion.count() << \" segundos\" << std::endl;\n",
        "\n",
        "        // Liberar memória\n",
        "        delete[] v;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LA8-TNIvc7K",
        "outputId": "206de8ce-b75a-4af4-c4ba-35ba4d256b6d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing variance_comparison2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc variance_comparison2.cu -o variance_comparison2"
      ],
      "metadata": {
        "id": "CYZIs4Vyvc-l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./variance_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQzZlxWOvym_",
        "outputId": "62039eac-4b75-41d5-a188-beddb891a577"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho N1 = 100000\n",
            "Variância CPU: 0.083289 | Tempo CPU: 0.000648772 segundos\n",
            "Variância GPU (etapas separadas): 0 | Tempo GPU: 0.000262605 segundos\n",
            "Variância GPU (fusion kernel): 0 | Tempo GPU: 5.31e-07 segundos\n",
            "\n",
            "Tamanho N2 = 1000000\n",
            "Variância CPU: 0.0832533 | Tempo CPU: 0.00675333 segundos\n",
            "Variância GPU (etapas separadas): 0 | Tempo GPU: 4.545e-06 segundos\n",
            "Variância GPU (fusion kernel): 0 | Tempo GPU: 5.2e-07 segundos\n"
          ]
        }
      ]
    }
  ]
}